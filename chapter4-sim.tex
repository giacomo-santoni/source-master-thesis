\label{simulation-section}
A detailed Monte Carlo simulation of the GRAIN detector was implemented to study its performances in reconstructing interactions in LAr using the two different imaging system technologies. It includes several steps, as shown in Fig. \ref{fig:sim-chain}: from the simulation of the detector geometries and the interactions inside the medium to the reconstruction and analysis. In the following, each step will be presented \cite{tesi-cicero}. 

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.13]{images/chap3/sim-chain.png}
    \caption{Diagram of the simulation and reconstruction chain \cite{tesi-cicero}.}
    \label{fig:sim-chain}
\end{figure}

\section{Geometry description}
The geometries relative to SAND and GRAIN volume and to the cameras are described through the Geometry Description Markup Language (GDML), a format based on the XML language, that is typically used with Geant4 and ROOT frameworks for the detector geometry description. 

The camera description (see Fig. \ref{fig:camera-sim}) includes a mask, a sensor, placed behind the mask, and a surrounding body. The mask is a 0.1~mm thick metal sheet with regular pattern of squared holes with a 3~mm side. The sensor is made of silicon, with typical dimensions 10 $\times$ 10 $\text{cm}^2$ like the effective mask area. The body is a metal box that covers the sensor, shielding it from undesired light. The scintillation photons produced in GRAIN volume pass through the holes of the mask and arrive on the sensor. Since the camera body is filled with LAr, photons can be produced inside the camera as well. The impact of this extraneous signal and a technique to mitigate it will be discussed in Chap. \ref{ML-chapter}. %The geometry of the cameras was optimized and tested using a point light source and muons in a volume filled with an Ar-mixture. %mettere immagini qua? 

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.35]{images/chap3/camera-simulation.png}
    \caption{Example of camera geometry: the mask (blue) and the sensor (red) are placed on opposite sides, the body (white) is 100\% opaque \cite{tesi-cicero}.}
    \label{fig:camera-sim}
\end{figure}

SAND geometry was implemented using the General Geometry Description software, suggested by the DUNE collaboration.  Shown in Fig. \ref{fig:sand-sim}, it contains all the parts described in Sec. \ref{sand-components}: in particular, GRAIN vessels are simulated according to an elliptical shape with major axis of 192.42 cm and minor axis of 85.4 cm and 193.2 cm of length for the outer vessel; axes of 72.8 cm and 23.75 cm with 150 cm of length for the inner one. 

The description of GRAIN cameras is implemented in a separate geometry. This geometry includes the inner vessels, with the same dimensions of the SAND simulation, and the cameras. In this way, it is possible to test many different camera and readout configurations with only one simulation of neutrino interactions in the SAND volume, leading to great flexibility.

\begin{figure}[h!]
    \centering
    \subfigure[]{\includegraphics[scale=0.14]{images/chap3/side-sand.png}}
    \subfigure[]{\includegraphics[scale=0.14]{images/chap3/front-sand.png}}
    \caption{X-Z (a) and X-Y (b) sections of the SAND detector geometry used in the simulation \cite{tesi-cicero}.}
    \label{fig:sand-sim}
\end{figure}

\section{Event generation and energy deposit}
For the generation of the neutrino interactions, the GENIE neutrino event generator, a ROOT-based MC software adopted by the DUNE collaboration \cite{GENIE}, was utilized. It simulates the primary neutrino-nucleon interactions, generating all the particles produced, and the following collisions that the recoiled nucleon makes with other nucleons. This can be accomplished since it includes the description of the main scattering mechanisms. For calibration and validation purposes we simulated other sources such as muon and simple light point directly in GEANT4. 

The propagation and the energy deposits of the generated particles are simulated by the Edep-sim software \cite{Edep-sim}, a wrapper around GEANT4. It gives information on the energy deposited through ionization and scintillation processes. In the case of LAr, the Noble Element Simulation Technique (NEST) \cite{NEST} is used by GEANT4: it is a collection of models that describe the energy loss by scintillation and ionization in noble elements as a function of electric field, particle type and incident energy or energy loss.

Summarizing the process, after a neutrino interaction is generated by GENIE, the file is processed by Edep-sim. Here, its output file contains information on the primary particles, on the trajectories of all the generated particles (also the ones produced in the propagation of the primaries) and on their energy deposit. In particular, Edep-sim documents the starting and stopping point of each energy deposit and the particle that generated it. 

\section{Optical simulation}
The output of Edep-sim is then processed by the photon propagation module of GEANT4 to simulate the optical scintillation emission by LAr in GRAIN. The simulation uses the information on energy deposit to emit, propagate and collect the scintillation photons in the simulated GRAIN geometry. The main processes that photons undergo during the propagation are Rayleigh scattering and absorption, for which constant lengths of $\lambda_{RS} = 90$ cm and $\lambda_{abs} = 5$ m, respectively, are fixed in the simulation, even if they are wavelength-dependent. The other input quantities for the simulation are the light yield, the decay times of singlet and triplet states, with the values presented in Sec. \ref{LAr-prop} (LAr properties). In addition, the reflection of the material inside the inner vessel must be considered: since we are developing an imaging system, the reflection must be as small as possible to avoid the detection of photons that are out of interest. Hence, in the simulation, the surface reflection is set to 0\%, with an absorption probability of 100\%. 

The sensor volume inside each camera acts as the detector of the simulation, collecting information on the photons that impinge on its surface. The relevant quantities are: the incident photon position, the direction on the sensor, its detection time and the photon energy. These information are contained in the optical simulation output, which consider 100\% efficiency without any fine structure of the image detector. Then, they are processed by another software to simulate the detector response. In this way, it is possible to test many different sensor and readout types with only one optical simulation.

\section{Detector response}
A standalone software is dedicated to the simulation of detector response to the collected photons. This tool, mainly written in Python, models the SiPM response and the properties of the electronics. It receives the information from the optical simulation and gives as output the number of photons detected by a SiPM matrix and the arrival time of the first photon for each pixel. The determination of how many photons interact on the sensor surface, among the total amount, relies on a random process. For each photon, a probability value $p$ is extracted from a uniform (0,1) distribution: if $p< \text{PDE}$, the photon is considered as interacting and an amplitude value is associated with it, taken randomly from a Gaussian distribution centered on the average amplitude value generated by a photoelectron. For each photon, a waveform is simulated (see Fig. \ref{fig:simulated-signal}) and then all the waveforms are summed together to get the total SiPM response.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/chap5/simulated-sipm-signal.jpg}
    \caption{Simulated SiPM signal. Note the long tail of separate photons due to the slow component of the argon scintillation (the red line indicates 0.5  p.e. threshold).}
    \label{fig:simulated-signal}
\end{figure}

\section{Photon source distribution reconstruction}
After the simulation of the detector response, that returns a map of the number of photons measured by each camera, the reconstruction algorithm can be applied. 

This process is based on the Maximum Likelihood Expectation Maximization (ML-EM) algorithm \cite{ML-EM}. It is an iterative method in which the measured data are considered samples of a set of random variables with p.d.f.s related to the object distribution, according to a mathematical model of the data acquisition process. Through this mathematical model, it is possible to compute the probability that any initial distribution density in the object studied could have produced the observed data. In the set of all possible images, which represent a potential object distribution, the image having the highest such probability is the \textit{maximum likelihood estimate} of the original object \cite{tesi-cicero}. This algorithm is suitable for a 3D application.
The volume is divided in voxels and for each voxel the algorithm computes the score, defined as:

\begin{equation}
    \lambda^{(k+1)}(j)=\frac{\lambda^{(k)}(j)}{\sum_{s=1}^S p(j, s)} \cdot \sum_{s=1}^S \frac{H(s) p(j, s)}{\sum_{j^{\prime}=1}^J \lambda^{(k)}\left(j^{\prime}\right) p\left(j^{\prime}, s\right)}, \quad \text { with } \quad \lambda^{(0)}=1.
\end{equation}

The probability matrix $p(j,s)$, called \textit{system matrix}, represents the probability with which an emission from a voxel $j$ is detected in a sensor pixel $s$; $H(s)$ is the measured number of photon hits in the sensor matrix pixel $s$ and $\lambda(j)$ is the unknown photon counts of voxel $j$ of the segmented volume of interest to be estimated from the measured data. 

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.25]{images/chap3/geom-prob.png}
    \caption{Diagram of the solid angle computation for different voxels and sensors, in the case of a Coded Aperture Mask. \cite{tesi-cicero}.}
    \label{fig:geom-prob}
\end{figure}

Inside the probability term the GRAIN geometry, the attenuation process of the scintillation photons during the propagation and the detector efficiency (i.e. the PDE) are taken into account, resulting in a product of: $p = p_{geom} \cdot p_{LAr} \cdot p_{sensor}$. The estimate of the geometric probability assumes that photons are emitted isotropically, propagate in a straight line and that the distance is large compared to the voxel size. In addition, it depends on the portion of the sensor area that can be seen through the mask holes from the given voxel. Fig. \ref{fig:geom-prob} shows an example: the voxel with center in A sees sensor 0 through two holes in the mask, and its solid angle is the sum of the angles subtended by the two portions of sensor area visible. For the voxel with center in B, the solid angle relative to sensor 1 is limited by the mask, while the sensor 3 is completely visible. \\ In this geometric model, the size of pixel edges and mask holes are taken into account, since they are non-negligible with respect to the sensitive area. The iterations, labelled with $k$, are currently fixed to 500 since it has been observed that further iterations do not improve the reconstruction. As output, the software returns a 3D array that contains the $\lambda$ values of the voxel scores of the reconstructed volume, where the score is an estimate of the number of photons emitted. This discussion considers only one camera, but the algorithm can be applied directly to multiple cameras, including the probabilities for all sensors in the system matrix.

The ML-EM is well suited for this application, but it has few drawbacks, such as the slow convergence rate and the high computational cost. For these reasons, the computations are performed on GPU, to complete the reconstruction in an acceptable time.

The next step is the simulation chain is the extraction of tracks from the reconstructed voxel clusters. This is the subject of this thesis and it will be presented in Chap. \ref{reco}.